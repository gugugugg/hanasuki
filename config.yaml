# =================================================================
# Project: Hanasuki AI Kernel Configuration
# Version: V10.0.0 (Qwen2.5 Optimized)
# =================================================================

system:
  name: "Hanasuki"
  version: "10.0.0"
  author: "lovesang"

model:
  backend: "llama_cpp"
  # [PATH]: ç¡®ä¿æ–‡ä»¶åä¸æ‚¨ä¸‹è½½çš„å®Œå…¨ä¸€è‡´
  path: "models/Josiefied-Qwen3-8B-abliterated-v1-q4_k_m.gguf"
  
  # âš¡ æ¨¡å¼ Aï¼šæ—¥å¸¸äº¤äº’ (å…¨æ˜¾å­˜åŠ é€Ÿ)
  profile_normal:
    n_gpu_layers: -1
    n_ctx: 8192        
    flash_attn: true
  
  # ğŸ§  æ¨¡å¼ Bï¼šæ·±åº¦è‡ªç ” (16k ä¸Šä¸‹æ–‡ä¸çˆ†æ˜¾å­˜)
  profile_learning:
    n_gpu_layers: -1   
    n_ctx: 16384       
    flash_attn: true

  temperature: 0.7

learning:
  idle_threshold: 180 # 3åˆ†é’Ÿé—²ç½®è§¦å‘è‡ªç ”
  max_retries: 2      # å·¥å…·æ‰§è¡Œå¤±è´¥åçš„è‡ªæˆ‘ä¿®æ­£æ¬¡æ•°

modules:
  # [LOCAL]: æœ¬åœ°è¯­ä¹‰æ¨¡å‹è·¯å¾„
  embedding_model: "E:/lovesang/hanasuki/models/embeddings/bge-small-zh-v1.5"
  vector_db_path: "data/vector_db"
  workspace_root: "workspace"