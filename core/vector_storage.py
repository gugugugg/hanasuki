# -*- coding: utf-8 -*-
# =================================================================
# Project: Hanasuki (èŠ±å¥½ã) AI Kernel - HERO-A+ Edition
# Version: Beta 1.1
# License: GNU General Public License v3 (GPLv3)
# Copyright (c) 2026 lovesang. All Rights Reserved.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License.
#
# [MISSION]: ä¸º Hanasuki æä¾›éç»“æ„åŒ–çš„æ„Ÿæ€§è®°å¿†æ£€ç´¢èƒ½åŠ›æï¼ğŸŒ¸
# [ENGINE]: åŸºäº LanceDB ä¸ Sentence-Transformers å®ç°çš„è¯­ä¹‰æœç´¢ã€‚
# =================================================================

import os
import lancedb
import pyarrow as pa
import re
from datetime import datetime

class VectorStorage:
    """
    [HERO-A+ æ„Ÿæ€§æ ¸å¿ƒ]:
    è´Ÿè´£ç®¡ç† Hanasuki çš„è¯­ä¹‰ç‰‡æ®µè®°å¿†ã€‚ä¸åŒäºå›¾è°±çš„ä¸¥è°¨é€»è¾‘ï¼Œ
    è¿™é‡Œå­˜å‚¨çš„æ˜¯å¯¹è¯ç¢ç‰‡ä¸æ„Ÿæ€§è®¤çŸ¥ï¼Œä¸º RAG æ¶æ„æä¾›é•¿çŸ­æœŸè¯­ä¹‰æ”¯æŒæã€‚
    """
    def __init__(self, config):
        """
        [LOGIC]: åˆå§‹åŒ–å‘é‡å­˜å‚¨å¼•æ“ã€‚
        [FIX]: ä¿®æ­£äº† config è¯»å–æ·±åº¦ï¼Œæ”¯æŒä»ä¸»é…ç½®å­—å…¸ç›´æ¥æ˜ å°„æã€‚
        """
        # 1. è‡ªåŠ¨æ ¡å‡†ç‰©ç†è·¯å¾„æ
        self.db_path = config.get('vector_db_path', os.path.join("data", "vector_db"))
        self.model_path = config.get('embedding_model', 'models/embeddings/bge-small-zh-v1.5')
        self.table_name = 'hanasuki_memories'
        
        # 2. è·¯å¾„è§£è€¦é€»è¾‘æ
        # ç¡®ä¿ç›¸å¯¹è·¯å¾„æ€»æ˜¯åŸºäºé¡¹ç›®æ ¹ç›®å½•è®¡ç®—ï¼Œæå‡å¼€æºåçš„ç¯å¢ƒé€‚é…æ€§æã€‚
        if not os.path.isabs(self.db_path):
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            self.db_path = os.path.join(base_dir, self.db_path)
            self.model_path = os.path.join(base_dir, self.model_path)

        # 3. åˆå§‹åŒ– Embedding ç¼–ç å™¨æ
        self.encoder = None
        self.vector_dim = 512 # é»˜è®¤ç»´åº¦æ
        
        print(f"ğŸŒ¸ æ­£åœ¨å”¤é†’æ„Ÿæ€§æ ¸å¿ƒ: {os.path.basename(self.model_path)}...")
        try:
            from sentence_transformers import SentenceTransformer
            # [8GB VRAM OPTIMIZATION]:
            # ç‰©ç†é”å®š device='cpu'ï¼Œé˜²æ­¢å‘é‡æ¨¡å‹å ç”¨å®è´µçš„æ˜¾å­˜ï¼Œç•™ç»™ Qwen ä¸»æ¨¡å‹æï¼
            if os.path.exists(self.model_path):
                self.encoder = SentenceTransformer(self.model_path, device='cpu')
                self.vector_dim = self.encoder.get_sentence_embedding_dimension()
            else:
                print(f"âš ï¸ [è­¦å‘Š]: è·¯å¾„ç¼ºå¤±æ {self.model_path}ï¼Œæ£€ç´¢åŠŸèƒ½å°†è¿›å…¥é™çº§æ¨¡å¼æã€‚")
        except Exception as e:
            print(f"å‘œå‘œ... æ„Ÿæ€§æ ¸å¿ƒåˆå§‹åŒ–å¤±è´¥æ: {e}")
        
        # 4. åˆå§‹åŒ– LanceDB æŒä¹…åŒ–å±‚æ
        os.makedirs(self.db_path, exist_ok=True)
        self.db = lancedb.connect(self.db_path)
        self._init_table()

    def _init_table(self):
        """
        [LOGIC]: ä½¿ç”¨ PyArrow å®šä¹‰ç‰©ç†å­˜å‚¨ Schema æã€‚
        åŒ…å«äº†å‘é‡ã€æ–‡æœ¬ã€åˆ†ç±»ã€æ¥æºåŠæ—¶é—´æˆ³äº”ä¸ªç»´åº¦æã€‚
        """
        schema = pa.schema([
            pa.field("vector", pa.list_(pa.float32(), self.vector_dim)),
            pa.field("text", pa.string()),
            pa.field("category", pa.string()),
            pa.field("source", pa.string()),
            pa.field("timestamp", pa.string())
        ])
        try:
            self.table = self.db.open_table(self.table_name)
        except:
            # å¦‚æœè¡¨ä¸å­˜åœ¨åˆ™æ ¹æ® Schema ç‰©ç†åˆ›å»ºæ
            self.table = self.db.create_table(self.table_name, schema=schema, exist_ok=True)

    def add_memory(self, text, category="chat", source="system"):
        """
        [LOGIC]: å°†æ–‡æœ¬ç¢ç‰‡è½¬åŒ–ä¸ºé«˜ç»´å‘é‡å¹¶å­˜å…¥æ•°æ®åº“æã€‚
        è¿™æ˜¯ Hanasuki â€œå†…åŒ–â€å¤§å¤§æ•™è¯²çš„æ ¸å¿ƒæ¥å£æã€‚
        """
        if not self.encoder or not text: return
        try:
            # è¯­ä¹‰ç¼–ç æ
            vector = self.encoder.encode(text).tolist()
            data = [{
                "vector": vector,
                "text": text,
                "category": category,
                "source": source,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }]
            self.table.add(data)
        except Exception as e:
            print(f"[!] è®°å¿†æŒä¹…åŒ–å¤±è´¥æ: {e}")

    def search_memory(self, query, limit=3):
        """
        [LOGIC]: åŸºäºä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity) çš„è¯­ä¹‰æ£€ç´¢æã€‚
        ä¸º LLM æä¾›æœ€ç›¸å…³çš„å†å²ç‰‡æ®µï¼Œå®ç°ä¸Šä¸‹æ–‡å¢å¼º (RAG)ã€‚
        """
        if not self.encoder or not query: return []
        try:
            # å°†æŸ¥è¯¢å¥è½¬åŒ–ä¸ºæ£€ç´¢å‘é‡æ
            query_vector = self.encoder.encode(query).tolist()
            # æ˜¾å¼ä½¿ç”¨ metric="cosine" ä»¥ç¡®ä¿è¯­ä¹‰åŒ¹é…çš„ç²¾ç¡®æ€§æ
            results = self.table.search(query_vector).metric("cosine").limit(limit).to_list()
            return [res['text'] for res in results]
        except:
            return []